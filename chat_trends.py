import pandas as pd
import streamlit as st
from collections import Counter
import nltk
from nltk.corpus import stopwords
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import numpy as np
import re
import requests
import configparser
from PIL import Image

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = configparser.ConfigParser()
config.read("config.ini", encoding="utf-8")
BOT_TOKEN = config["TELEGRAM"]["BOT_TOKEN"]
CHAT_IDS = [int(chat.strip()) for chat in config["TELEGRAM"]["CHAT_IDS"].split(",") if chat.strip()]

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
nltk.download("stopwords")
stop_words = set(stopwords.words("russian"))

def load_chat_data():
    try:
        df = pd.read_csv("chat_activity.csv", names=["timestamp", "user_id", "username", "message"])
        return df
    except FileNotFoundError:
        st.error("–§–∞–π–ª chat_activity.csv –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return pd.DataFrame(columns=["timestamp", "user_id", "username", "message"])

# –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
def clean_text(text):
    text = re.sub(r"[^\w\s]", "", text.lower())
    words = text.split()
    return [word for word in words if word not in stop_words and len(word) > 2]

# –ê–Ω–∞–ª–∏–∑ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö —Å–ª–æ–≤
def analyze_trends(df):
    if df.empty:
        return {}
    all_words = []
    for message in df["message"].dropna():
        all_words.extend(clean_text(message))
    return dict(Counter(all_words).most_common(50))

# –û—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ Telegram
def send_trends_to_telegram(word_freq):
    if not word_freq:
        return
    
    text = "üìä *–¢—Ä–µ–Ω–¥—ã –æ–±—Å—É–∂–¥–µ–Ω–∏–π –≤ —á–∞—Ç–∞—Ö:*\n"
    for word, count in word_freq.items():
        text += f"üîπ {word}: {count} —Ä–∞–∑\n"
    
    for chat_id in CHAT_IDS:
        requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            json={"chat_id": chat_id, "text": text, "parse_mode": "Markdown"}
        )

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤ –≤ —Ñ–æ—Ä–º–µ —Å–ª–æ–≤–∞ NeuroFlex
def generate_neuroflex_wordcloud(word_freq):
    mask = np.array(Image.open("neuroflex_mask.png"))  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ñ–æ—Ä–º–æ–π —Ç–µ–∫—Å—Ç–∞ "NeuroFlex"
    wordcloud = WordCloud(width=800, height=400, background_color="white", mask=mask, contour_width=3, contour_color='black')
    wordcloud.generate_from_frequencies(word_freq)
    return wordcloud

# Streamlit UI
st.title("5Ô∏è‚É£ –¢—Ä–µ–Ω–¥—ã –æ–±—Å—É–∂–¥–µ–Ω–∏–π –≤ —á–∞—Ç–∞—Ö")
df = load_chat_data()
word_freq = analyze_trends(df)

if word_freq:
    st.subheader("üìå –°–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–µ–º—ã")
    st.write(pd.DataFrame(word_freq.items(), columns=["–°–ª–æ–≤–æ", "–ß–∞—Å—Ç–æ—Ç–∞"]))
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤
    st.subheader("‚òÅ –û–±–ª–∞–∫–æ —Å–ª–æ–≤ –≤ —Ñ–æ—Ä–º–µ 'NeuroFlex'")
    wordcloud = generate_neuroflex_wordcloud(word_freq)
    fig, ax = plt.subplots()
    ax.imshow(wordcloud, interpolation="bilinear")
    ax.axis("off")
    st.pyplot(fig)
    
    if st.button("üì§ –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç—Ä–µ–Ω–¥—ã –≤ Telegram"):
        send_trends_to_telegram(word_freq)
        st.success("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞!")
else:
    st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
